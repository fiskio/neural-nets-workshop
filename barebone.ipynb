{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- setup some useful stuff\n",
    "require 'nn'\n",
    "\n",
    "-- setting the random generator seed\n",
    "torch.manualSeed(42)\n",
    "\n",
    "-- help function to print in green\n",
    "function cprint(str) print(sys.COLORS.green..str..'\\27[0m') end\n",
    "\n",
    "-- tests\n",
    "precision = 1e-5\n",
    "tester = torch.Tester()\n",
    "function runTest(test)\n",
    "    tester:add(test)\n",
    "    tester:run()\n",
    "    tester = torch.Tester()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Lookup Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running 1 tests\t\n",
       "_\r",
       "\r",
       "\r",
       "|  ==> unknown\n",
       "\u001b[0;32mLookupTable weight is now:\u001b[0m\t\n",
       "  1   4   7  10  13\n",
       "  2   5   8  11  14\n",
       "  3   6   9  12  15\n",
       "[torch.DoubleTensor of dimension 3x5]\n",
       "\n",
       "\u001b[0;32mLookupTable has no bias!\u001b[0m\t\n",
       "\u001b[0;32mTesting input matrix is:\u001b[0m\t\n",
       " 1  2\n",
       " 3  4\n",
       "[torch.DoubleTensor of dimension 2x2]\n",
       "\n",
       "\u001b[0;32mExpected output is:\u001b[0m\t\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1,.,.) = \n",
       "   1   7\n",
       "   2   8\n",
       "   3   9\n",
       "\n",
       "(2,.,.) = \n",
       "   4  10\n",
       "   5  11\n",
       "   6  12\n",
       "[torch.DoubleTensor of dimension 2x3x2]\n",
       "\n",
       "2\t\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       "[torch.LongTensor of dimension 4]\n",
       "\n",
       "  1   2   3\n",
       "  4   5   6\n",
       "  7   8   9\n",
       " 10  11  12\n",
       "[torch.DoubleTensor of dimension 4x3]\n",
       "\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\r",
       "              \r",
       "*  ==> Done \n",
       "\n",
       "Completed 1 asserts in 1 tests with 1 errors\t\n",
       "\n",
       "--------------------------------------------------------------------------------\t\n",
       "unknown\n",
       " Function call failed \n",
       "/home/fiskio/torch/install/share/lua/5.1/torch/Tensor.lua:450: expecting a contiguous tensor\n",
       "stack traceback:\n",
       "\t[C]: in function 'assert'\n",
       "\t/home/fiskio/torch/install/share/lua/5.1/torch/Tensor.lua:450: in function 'forward'\n",
       "\t[string \"lookupTable = function(vocabSize, embeddingSi...\"]:58: in function <[string \"lookupTable = function(vocabSize, embeddingSi...\"]:31>\n",
       "\t[C]: in function 'xpcall'\n",
       "\t/home/fiskio/torch/install/share/lua/5.1/torch/Tester.lua:112: in function 'pcall'\n",
       "\t/home/fiskio/torch/install/share/lua/5.1/torch/Tester.lua:169: in function 'run'\n",
       "\t[string \"-- setup some useful stuff...\"]:15: in function 'runTest'\n",
       "\t[string \"lookupTable = function(vocabSize, embeddingSi...\"]:31: in main chunk\n",
       "\t[C]: in function 'xpcall'\n",
       "\t/home/fiskio/torch/install/share/lua/5.1/itorch/main.lua:174: in function </home/fiskio/torch/install/share/lua/5.1/itorch/main.lua:140>\n",
       "\t/home/fiskio/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n",
       "\t/home/fiskio/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n",
       "\t/home/fiskio/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n",
       "\t/home/fiskio/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n",
       "\t/home/fiskio/torch/install/share/lua/5.1/itorch/main.lua:341: in main chunk\n",
       "\t[C]: in function 'require'\n",
       "\t(command line):1: in main chunk\n",
       "\t[C]: at 0x00406170\n",
       "\t\n",
       "--------------------------------------------------------------------------------\t\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookupTable = function(vocabSize, embeddingSize)\n",
    "    -- module to build\n",
    "    local this = {}\n",
    "    \n",
    "    -- standard deviation for initialization\n",
    "    local stdv =  1./math.sqrt(embeddingSize)\n",
    "    \n",
    "    -- weight matrix\n",
    "    this.weight = torch.Tensor(embeddingSize, vocabSize):uniform(-stdv, stdv)\n",
    "    \n",
    "    -- forward operation\n",
    "    this.forward = function(input)\n",
    "        -- quirk to make it work with vectors and matrices\n",
    "        input = (input:dim() == 1) and input:reshape(input:size(1), 1) or input\n",
    "        -- how many words? how many samples?\n",
    "        local nWords = input:size(1)\n",
    "        local nSamples = input:size(2)\n",
    "        print(nSamples)\n",
    "        -- view matrix as vector to be used as index\n",
    "        local vectorView = torch.view(input:long(), -1)\n",
    "        print(vectorView)\n",
    "        local output = this.weight:index(2, vectorView)\n",
    "        print(output)\n",
    "        return torch.view(output, nSamples, embeddingSize, nWords)\n",
    "    end\n",
    "    \n",
    "    return this\n",
    "end\n",
    "\n",
    "-- test\n",
    "runTest(function()\n",
    "    print()\n",
    "    -- 5 words with embeddings of size 3\n",
    "    local dictionary = lookupTable(5,3)\n",
    "    dictionary.weight = torch.range(1,15):reshape(5,3):t()\n",
    "    cprint('LookupTable weight is now:')\n",
    "    print(dictionary.weight)\n",
    "    cprint('LookupTable has no bias!')\n",
    "    tester:assert(dictionary.bias == nil)\n",
    "\n",
    "    local inputVector = torch.Tensor{1,3,5}\n",
    "    cprint('Testing input vector is:')\n",
    "    print(inputVector)\n",
    "    local expected = torch.Tensor{{1,2,3},{7,8,9},{13,14,15}}:t():reshape(1, 3, 3)\n",
    "    cprint('Expected output is:')\n",
    "    print(expected)\n",
    "    local output = dictionary.forward(inputVector)\n",
    "    cprint('Actual output is:')\n",
    "    print(output)\n",
    "    tester:assertTensorEq(expected, output, precision)\n",
    "\n",
    "    local inputMatrix = torch.Tensor{{1,3},{2,4}}:t()\n",
    "    cprint('Testing input matrix is:')\n",
    "    print(inputMatrix)\n",
    "    local expected = torch.Tensor{{1,2,3},{7,8,9},{4,5,6},{10,11,12}}:reshape(2, 2, 3):transpose(2, 3)\n",
    "    cprint('Expected output is:')\n",
    "    print(expected)\n",
    "    local output = dictionary.forward(inputMatrix)\n",
    "    cprint('Actual output is:')\n",
    "    print(output)\n",
    "    tester:assertTensorEq(expected, output, precision)\n",
    "end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Linear Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running 1 tests\t\n",
       "_\r",
       "\r",
       "\r",
       "|  ==> unknown\n",
       "\u001b[0;32mLinearModule weight is now:\u001b[0m\t\n",
       " 2  2\n",
       " 2  2\n",
       " 2  2\n",
       "[torch.DoubleTensor of dimension 3x2]\n",
       "\n",
       "\u001b[0;32mLinearModule bias is now:\u001b[0m\t\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.DoubleTensor of dimension 3x1]\n",
       "\n",
       "\u001b[0;32mTesting input vector is:\u001b[0m\t\n",
       "-1\n",
       "-1\n",
       "[torch.DoubleTensor of dimension 2]\n",
       "\n",
       "\u001b[0;32mExpected output is:\u001b[0m\t\n",
       "-3\n",
       "-3\n",
       "-3\n",
       "[torch.DoubleTensor of dimension 3x1]\n",
       "\n",
       "\u001b[0;32mActual output is:\u001b[0m\t\n",
       "-3\n",
       "-3\n",
       "-3\n",
       "[torch.DoubleTensor of dimension 3x1]\n",
       "\n",
       "\u001b[0;32mTesting input matrix is:\u001b[0m\t\n",
       " 2  2  2\n",
       " 2  2  2\n",
       "[torch.DoubleTensor of dimension 2x3]\n",
       "\n",
       "\u001b[0;32mExpected output is:\u001b[0m\t\n",
       " 9  9  9\n",
       " 9  9  9\n",
       " 9  9  9\n",
       "[torch.DoubleTensor of dimension 3x3]\n",
       "\n",
       "\u001b[0;32mActual output is:\u001b[0m\t\n",
       " 9  9  9\n",
       " 9  9  9\n",
       " 9  9  9\n",
       "[torch.DoubleTensor of dimension 3x3]\n",
       "\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\r",
       "              \r",
       "_  ==> Done \n",
       "\n",
       "Completed 2 asserts in 1 tests with 0 errors\t\n",
       "\n",
       "--------------------------------------------------------------------------------\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearModule = function(inputSize, outputSize)\n",
    "    \n",
    "    -- module to build\n",
    "    local this = {}\n",
    "    \n",
    "    -- standard deviation for initialization\n",
    "    local stdv =  1./math.sqrt(outputSize)\n",
    "    \n",
    "    -- weight matrix\n",
    "    this.weight = torch.Tensor(outputSize, inputSize):uniform(-stdv, stdv)\n",
    "    \n",
    "    -- bias vector\n",
    "    this.bias = torch.Tensor(outputSize, 1):uniform(-stdv, stdv)\n",
    "    \n",
    "    -- forward operation\n",
    "    this.forward = function(input)\n",
    "        -- quirk to make it work with vectors and matrices\n",
    "        input = (input:dim() == 1) and input:reshape(input:size(1), 1) or input\n",
    "        -- multiply the input and weight matrix\n",
    "        local output = this.weight * input\n",
    "        -- add the expanded bias vector and return\n",
    "        return output + this.bias:expand(output:size())\n",
    "    end\n",
    "\n",
    "    return this\n",
    "end\n",
    "\n",
    "-- test\n",
    "runTest(function()\n",
    "    print()\n",
    "    local layer = linearModule(2,3)\n",
    "    layer.weight:fill(2)\n",
    "    layer.bias:fill(1)\n",
    "    cprint('LinearModule weight is now:')\n",
    "    print(layer.weight)\n",
    "    cprint('LinearModule bias is now:')\n",
    "    print(layer.bias)\n",
    "\n",
    "    local inputVector = torch.Tensor(2):fill(-1)\n",
    "    cprint('Testing input vector is:')\n",
    "    print(inputVector)\n",
    "    local expected = torch.Tensor(3,1):fill(-3)\n",
    "    cprint('Expected output is:')\n",
    "    print(expected)\n",
    "    local output = layer.forward(inputVector)\n",
    "    cprint('Actual output is:')\n",
    "    print(output)\n",
    "    tester:assertTensorEq(expected, output, precision)\n",
    "\n",
    "    local inputMatrix = torch.Tensor(2, 3):fill(2)\n",
    "    cprint('Testing input matrix is:')\n",
    "    print(inputMatrix)\n",
    "    local expected = torch.Tensor(3,3):fill(9)\n",
    "    cprint('Expected output is:')\n",
    "    print(expected)\n",
    "    local output = layer.forward(inputMatrix)\n",
    "    cprint('Actual output is:')\n",
    "    print(output)\n",
    "    tester:assertTensorEq(expected, output, precision)\n",
    "end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Sigmoid\n",
    "\\begin{equation*}\n",
    "    Sigmoid(x_i) = \\frac{1}{1 + e^{-x_i}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running 1 tests\t\n",
       "_\r",
       "\r",
       "\r",
       "|  ==> unknown\n",
       "\u001b[0;32mTesting input vector is:\u001b[0m\t\n",
       " 1\n",
       " 2\n",
       " 3\n",
       "[torch.DoubleTensor of dimension 3]\n",
       "\n",
       "\u001b[0;32mExpected output is:\u001b[0m\t\n",
       " 0.7311\n",
       " 0.8808\n",
       " 0.9526\n",
       "[torch.DoubleTensor of dimension 3]\n",
       "\n",
       "\u001b[0;32mActual output is:\u001b[0m\t\n",
       " 0.7311\n",
       " 0.8808\n",
       " 0.9526\n",
       "[torch.DoubleTensor of dimension 3]\n",
       "\n",
       "\u001b[0;32mTesting input matrix is:\u001b[0m\t\n",
       " 1  2  3\n",
       " 4  5  6\n",
       " 7  8  9\n",
       "[torch.DoubleTensor of dimension 3x3]\n",
       "\n",
       "\u001b[0;32mExpected output is:\u001b[0m\t\n",
       " 0.7311  0.8808  0.9526\n",
       " 0.9820  0.9933  0.9975\n",
       " 0.9991  0.9997  0.9999\n",
       "[torch.DoubleTensor of dimension 3x3]\n",
       "\n",
       "\u001b[0;32mActual output is:\u001b[0m\t\n",
       " 0.7311  0.8808  0.9526\n",
       " 0.9820  0.9933  0.9975\n",
       " 0.9991  0.9997  0.9999\n",
       "[torch.DoubleTensor of dimension 3x3]\n",
       "\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\r",
       "              \r",
       "_  ==> Done \n",
       "\n",
       "Completed 2 asserts in 1 tests with 0 errors\t\n",
       "\n",
       "--------------------------------------------------------------------------------\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid = function(input)\n",
    "    return torch.exp(input):pow(-1):add(1):pow(-1)\n",
    "end\n",
    "\n",
    "-- test\n",
    "runTest(function()\n",
    "    print()\n",
    "    local inputVector = torch.range(1,3)\n",
    "    cprint('Testing input vector is:')\n",
    "    print(inputVector)\n",
    "    local expected = nn.Sigmoid():forward(inputVector)\n",
    "    cprint('Expected output is:')\n",
    "    print(expected)\n",
    "    local output = sigmoid(inputVector)\n",
    "    cprint('Actual output is:')\n",
    "    print(output)\n",
    "    tester:assertTensorEq(expected, output, precision)\n",
    "        \n",
    "    local inputMatrix = torch.range(1,9):reshape(3,3)\n",
    "    cprint('Testing input matrix is:')\n",
    "    print(inputMatrix)\n",
    "    local expected = nn.Sigmoid():forward(inputMatrix)\n",
    "    cprint('Expected output is:')\n",
    "    print(expected)\n",
    "    local output = sigmoid(inputMatrix)\n",
    "    cprint('Actual output is:')\n",
    "    print(output)\n",
    "    tester:assertTensorEq(expected, output, precision)\n",
    "end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogSoftMax\n",
    "\\begin{equation*}\n",
    "   LogSoftMax(x_i) = -\\ln \\Bigl(\\frac{1}{e^{x_i}} \\sum_j e^{x_j}\\Bigr)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running 1 tests\t\n",
       "_\r",
       "\r",
       "\r",
       "|  ==> unknown\n",
       "\u001b[0;32mInput matrix is:\u001b[0m\t\n",
       " 1  2  3\n",
       " 4  5  6\n",
       " 7  8  9\n",
       "[torch.DoubleTensor of dimension 3x3]\n",
       "\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;32mOutput from nn.LogSoftMax is:\u001b[0m\t\n",
       "-2.4076 -1.4076 -0.4076\n",
       "-2.4076 -1.4076 -0.4076\n",
       "-2.4076 -1.4076 -0.4076\n",
       "[torch.DoubleTensor of dimension 3x3]\n",
       "\n",
       "\u001b[0;32mOutput from logSoftMax is:\u001b[0m\t\n",
       "-2.4076 -1.4076 -0.4076\n",
       "-2.4076 -1.4076 -0.4076\n",
       "-2.4076 -1.4076 -0.4076\n",
       "[torch.DoubleTensor of dimension 3x3]\n",
       "\n",
       "\r",
       "              \r",
       "_  ==> Done \n",
       "\n",
       "Completed 1 asserts in 1 tests with 0 errors\t\n",
       "\n",
       "--------------------------------------------------------------------------------\t\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logSoftMax = function(input) \n",
    "    \n",
    "    -- quirk to make it work with vectors and matrices\n",
    "    input = (input:dim() == 1) and input:reshape(input:size(1), 1) or input\n",
    "    \n",
    "    -- calculate sum of e^x_i and expand it to the right size\n",
    "    local sumOfExp = torch.exp(input):sum(2):expand(input:size())\n",
    "    \n",
    "    -- calculate the rest of the formula and return\n",
    "    return torch.exp(input):pow(-1):cmul(sumOfExp):log():mul(-1)\n",
    "end\n",
    "\n",
    "-- test\n",
    "runTest(function()\n",
    "    print()\n",
    "    input = torch.range(1,9):reshape(3,3)\n",
    "    cprint('Input matrix is:')\n",
    "    print(input)\n",
    "    local lms = nn.LogSoftMax()\n",
    "    local expected = lms:forward(input)\n",
    "    cprint('Output from nn.LogSoftMax is:')\n",
    "    print(expected)\n",
    "    local output = logSoftMax(input)\n",
    "    cprint('Output from logSoftMax is:')\n",
    "    print(output)\n",
    "    tester:assertTensorEq(expected, output, 1e-5)\n",
    "end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Negative Log-Likelihood\n",
    "\n",
    "\\begin{equation*}\n",
    "    C = -\\ln a^L_y\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negativeLogLikelihood = function(input, class)\n",
    "    return input:log():mul(-1)[class]\n",
    "end\n",
    "\n",
    "-- test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"-- network parameters...\"]:9: attempt to call global 'linearModule' (a nil value)\nstack traceback:\n\t[string \"-- network parameters...\"]:9: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/fiskio/torch/install/share/lua/5.1/itorch/main.lua:174: in function </home/fiskio/torch/install/share/lua/5.1/itorch/main.lua:140>\n\t/home/fiskio/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/home/fiskio/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/home/fiskio/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/home/fiskio/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/fiskio/torch/install/share/lua/5.1/itorch/main.lua:341: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406170",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"-- network parameters...\"]:9: attempt to call global 'linearModule' (a nil value)\nstack traceback:\n\t[string \"-- network parameters...\"]:9: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/fiskio/torch/install/share/lua/5.1/itorch/main.lua:174: in function </home/fiskio/torch/install/share/lua/5.1/itorch/main.lua:140>\n\t/home/fiskio/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/home/fiskio/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/home/fiskio/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/home/fiskio/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/fiskio/torch/install/share/lua/5.1/itorch/main.lua:341: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406170"
     ]
    }
   ],
   "source": [
    "-- network parameters\n",
    "local embeddingSize = 2\n",
    "local contextLength = 3\n",
    "local vocabSize = 5\n",
    "local hiddenSize = 6\n",
    "local stdv = 1\n",
    "\n",
    "-- IndexToEmbedding\n",
    "local lookupTable = linearModule(vocabSize, embeddingSize)\n",
    "cprint('LookupTable of '..vocabSize..' words, each is a vector of size '..embeddingSize)\n",
    "print(lookupTable.weight)\n",
    "print(lookupTable.bias)\n",
    "\n",
    "-- ContextToHidden\n",
    "local contextToHidden = linearModule(contextLength * embeddingSize, hiddenSize)\n",
    "cprint('Context-To-Hidden matrix is:')\n",
    "print(contextToHidden.weight)\n",
    "print(contextToHidden.bias)\n",
    "\n",
    "local hiddenToEmbedding = torch.FloatTensor(embeddingSize, hiddenSize):uniform(-stdv, stdv)\n",
    "\n",
    "cprint('Hidden-To-Embedding matrix is:')\n",
    "print(hiddenToEmbedding)\n",
    "\n",
    "local embeddingToVocabulary = torch.FloatTensor(vocabSize, embeddingSize):uniform(-stdv, stdv)\n",
    "\n",
    "cprint('Embedding-To-Vocabulary matrix is:')\n",
    "print(embeddingToVocabulary)\n",
    "\n",
    "function softMax(matrix)\n",
    "   -- -log(sum(exp(matrix)) * 1/exp(matrix))\n",
    "   return torch.mul(torch.exp(matrix):pow(-1), torch.sum(torch.exp(matrix), 1)[1]):log():mul(-1)\n",
    "end\n",
    "\n",
    "-- Forward\n",
    "--[[\n",
    "local oneHot = torch.FloatTensor():eye(vocabSize)\n",
    "cprint('1-Hot representation of second word is:')\n",
    "print(oneHot[2])\n",
    "\n",
    "local secondWord = torch.mv(lookupTable, oneHot[2])\n",
    "cprint('Vector representation of second word is:')\n",
    "print(secondWord)\n",
    "--]]\n",
    "local oneHotIndices = torch.LongTensor{1,3,5}\n",
    "cprint('Context will be built of words at indices...')\n",
    "print(oneHotIndices)\n",
    "\n",
    "local contextMatrix = lookupTable:index(2, oneHotIndices)\n",
    "cprint('...which corresponds to the following matrix:')\n",
    "print(oneHotContext)\n",
    "--[[\n",
    "local contextMatrix = torch.mm(lookupTable, oneHotContext)\n",
    "cprint('The corresponding matrix of embeddings are:')\n",
    "print(contextMatrix)\n",
    "--]]\n",
    "local contextVector = torch.reshape(contextMatrix, contextMatrix:nElement())\n",
    "cprint('...which reshaped as a vector is:')\n",
    "print(contextVector)\n",
    "\n",
    "local output = contextToHidden * contextVector\n",
    "print(output)\n",
    "\n",
    "output = torch.mv(hiddenToEmbedding, output)\n",
    "print(output)\n",
    "\n",
    "output = torch.mv(embeddingToVocabulary, output)\n",
    "print(output)\n",
    "\n",
    "output = softMax(output)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
